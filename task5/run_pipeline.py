"""
–û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.
"""

import os
os.environ['TCL_LIBRARY'] = "C:/Program Files/Python313/tcl/tcl8.6"
os.environ['TK_LIBRARY'] = "C:/Program Files/Python313/tcl/tk8.6"
import sys
import numpy as np
import pandas as pd
import torch
import json
import time
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç—ã –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from preprocessing import TimeSeriesPreprocessor
from feature_engineering import FeatureEngineer
from models import create_all_models
from training import train_model, ModelTrainer
from evaluation import MetricsCalculator, ModelEvaluator
from diagnostics import ModelDiagnostics

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞
torch.manual_seed(42)
np.random.seed(42)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")


class DeepLearningPipeline:
    """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤."""
    
    def __init__(self, data_path, target_column='Weekly_Sales', date_column='Date',
                 output_dir='results', lookback=336, horizon=48):
        self.data_path = data_path
        self.target_column = target_column
        self.date_column = date_column
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.lookback = lookback
        self.horizon = horizon
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.preprocessor = TimeSeriesPreprocessor(scaler_type='standard')
        self.feature_engineer = FeatureEngineer()
        self.metrics_calc = MetricsCalculator()
        self.evaluator = ModelEvaluator()
        self.diagnostics = ModelDiagnostics()
        
        # –î–∞–Ω–Ω—ã–µ
        self.df = None
        self.y = None
        self.dates = None
        self.train_data = None
        self.val_data = None
        self.test_data = None
        self.preprocessor_info = None
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.models = {}
        self.results = {}
        
    def load_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ."""
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        self.df = pd.read_csv(self.data_path)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç
        self.df[self.date_column] = pd.to_datetime(self.df[self.date_column], utc=True)
        if self.df[self.date_column].dt.tz is not None:
            self.df[self.date_column] = self.df[self.date_column].dt.tz_localize(None)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        self.df = self.df.sort_values(self.date_column)
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
        if self.target_column in self.df.columns:
            print(f"–î–∏–∞–ø–∞–∑–æ–Ω {self.target_column}: [{self.df[self.target_column].min():.2f}, {self.df[self.target_column].max():.2f}]")
            print(f"–°—Ä–µ–¥–Ω–µ–µ: {self.df[self.target_column].mean():.2f}, –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {self.df[self.target_column].std():.2f}")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ Store –∏ Dept
        if 'Store' in self.df.columns and 'Dept' in self.df.columns:
            n_stores = self.df['Store'].nunique()
            n_depts = self.df['Dept'].nunique()
            print(f"–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ: {n_stores} –º–∞–≥–∞–∑–∏–Ω–æ–≤, {n_depts} –æ—Ç–¥–µ–ª–æ–≤")
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º –∏ –æ—Ç–¥–µ–ª–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ)
            self.df = self.df.groupby(self.date_column)[self.target_column].mean().reset_index()
            self.df = self.df.set_index(self.date_column).sort_index()
            
            if len(self.df) < 200:
                print(f"‚ö†Ô∏è –ü–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏: {len(self.df)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π (–º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)")
        else:
            if self.date_column in self.df.columns:
                self.df = self.df.set_index(self.date_column)
        
        self.y = self.df[self.target_column].dropna()
        self.dates = self.y.index
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.y)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        print(f"–ü–µ—Ä–∏–æ–¥: {self.dates.min()} - {self.dates.max()}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
        if len(self.dates) > 1:
            freq = pd.infer_freq(self.dates)
            if freq is None:
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –ø–æ —Ä–∞–∑–Ω–∏—Ü–µ –¥–∞—Ç
                time_diff = (self.dates[1] - self.dates[0]).days
                if time_diff == 7:
                    freq = 'W'
                elif time_diff == 1:
                    freq = 'D'
                else:
                    freq = f'{time_diff}D'
            print(f"–ß–∞—Å—Ç–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {freq}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        if len(self.y) < 100:
            warnings.warn(f"–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {len(self.y)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. "
                        f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.")
        
        return self
    
    def preprocess_data(self, apply_transform='boxcox'):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö."""
        print("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º lookback –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
        n = len(self.y)
        min_required = self.lookback + self.horizon
        
        if n < min_required:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–º–µ–Ω—å—à–∞–µ–º lookback
            new_lookback = max(24, min(n - self.horizon - 10, self.lookback))
            if new_lookback != self.lookback:
                print(f"–ê–¥–∞–ø—Ç–∞—Ü–∏—è lookback: {self.lookback} -> {new_lookback} "
                      f"(–¥–æ—Å—Ç—É–ø–Ω–æ {n} —Ç–æ—á–µ–∫, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º {min_required})")
                self.lookback = new_lookback
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        (X_train, y_train, train_dates), \
        (X_val, y_val, val_dates), \
        (X_test, y_test, test_dates), \
        self.preprocessor_info = self.preprocessor.prepare_data(
            self.y, 
            lookback=self.lookback,
            horizon=self.horizon,
            apply_transform=apply_transform
        )
        
        self.train_data = (X_train, y_train, train_dates)
        self.val_data = (X_val, y_val, val_dates)
        self.test_data = (X_test, y_test, test_dates)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º lookback –∏ horizon –∏–∑ preprocessor_info (–º–æ–≥—É—Ç –±—ã—Ç—å —É–º–µ–Ω—å—à–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        self.lookback = self.preprocessor_info.get('lookback', self.lookback)
        self.horizon = self.preprocessor_info.get('horizon', self.horizon)
        
        print(f"Train: {len(X_train)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        print(f"Val: {len(X_val)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        print(f"Test: {len(X_test)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        print(f"–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: lookback={self.lookback}, horizon={self.horizon}")
        
        return self
    
    def train_all_models(self, model_names=None, epochs=100, batch_size=32):
        """–û–±—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏."""
        if model_names is None:
            # –ë–∞–∑–æ–≤—ã–µ –∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–±—ã—Å—Ç—Ä—ã–µ)
            model_names = ['MLP', 'TCN', 'N-BEATS', 'N-HiTS', 'RNN', 'LSTM', 'GRU', 
                          'BiLSTM', 'BiGRU', 'Transformer', 'CNN-LSTM', 'CNN-GRU',
                          'DLinear', 'NLinear', 'Naive', 'SeasonalNaive']
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏ (–º–µ–¥–ª–µ–Ω–Ω—ã–µ, –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
            # model_names += ['Informer', 'Autoformer', 'PatchTST', 'TFT', 'TCN-Attention', 'LSTM-AE']
        
        X_train, y_train, _ = self.train_data
        X_val, y_val, _ = self.val_data
        
        input_size = X_train.shape[2] if len(X_train.shape) == 3 else X_train.shape[1]
        
        print(f"\n–û–±—É—á–µ–Ω–∏–µ {len(model_names)} –º–æ–¥–µ–ª–µ–π...")
        print(f"Input size: {input_size}, Horizon: {self.horizon}")
        
        for model_name in model_names:
            try:
                print(f"\n{'='*60}")
                print(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
                print(f"{'='*60}")
                
                # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
                model = create_all_models(input_size, horizon=self.horizon, lookback=self.lookback)[model_name]
                
                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
                trainer_kwargs = {
                    'loss_fn': 'mse+mae',
                    'optimizer': 'adam',
                    'lr': 1e-3,
                    'weight_decay': 1e-4,
                    'gradient_clip': 1.0,
                    'early_stopping_patience': 15,
                    'reduce_lr_patience': 10,
                }
                
                # –û–±—É—á–∞–µ–º
                start_time = time.time()
                trainer, train_losses, val_losses = train_model(
                    model, X_train, y_train, X_val, y_val,
                    batch_size=batch_size,
                    epochs=epochs,
                    device=device,
                    verbose=True,  # –í–∫–ª—é—á–∞–µ–º –≤—ã–≤–æ–¥ –¥–ª—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
                    **trainer_kwargs
                )
                train_time = time.time() - start_time
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                from training import TimeSeriesDataset
                from torch.utils.data import DataLoader
                
                # –û–¢–õ–ê–î–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º DataLoader
                print(f"üîç –û–¢–õ–ê–î–ö–ê –¥–ª—è {model_name}:")
                print(f"  X_val —Ñ–æ—Ä–º–∞: {X_val.shape}, –¥–∏–∞–ø–∞–∑–æ–Ω: [{X_val.min():.6f}, {X_val.max():.6f}]")
                print(f"  y_val —Ñ–æ—Ä–º–∞: {y_val.shape}, –¥–∏–∞–ø–∞–∑–æ–Ω: [{y_val.min():.6f}, {y_val.max():.6f}]")
                print(f"  y_val –ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏:\n{y_val[:3] if len(y_val) >= 3 else y_val}")
                print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ y_val (–ø–µ—Ä–≤—ã–µ 10): {np.unique(y_val.flatten())[:10]}")
                
                val_dataset = TimeSeriesDataset(X_val, y_val)
                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
                y_pred_val, y_true_val = trainer.predict(val_loader)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –≤ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö
                if np.any(np.isnan(y_pred_val)) or np.any(np.isinf(y_pred_val)):
                    print(f"‚ö†Ô∏è –û–®–ò–ë–ö–ê: NaN/inf –≤ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö –¥–ª—è {model_name}!")
                    continue
                
                # –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
                if len(y_pred_val.shape) > 1:
                    y_pred_val_flat = y_pred_val[:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
                    y_true_val_flat = y_true_val[:, 0]
                else:
                    y_pred_val_flat = y_pred_val
                    y_true_val_flat = y_true_val
                
                # –û–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                y_pred_val_scaled = self.preprocessor.inverse_transform(y_pred_val_flat)
                y_true_val_scaled = self.preprocessor.inverse_transform(y_true_val_flat)
                
                if np.any(np.isnan(y_pred_val_scaled)) or np.any(np.isinf(y_pred_val_scaled)):
                    y_pred_val_scaled = np.nan_to_num(y_pred_val_scaled, nan=0.0, posinf=1e10, neginf=-1e10)
                
                # –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è (Box-Cox –∏–ª–∏ log)
                if self.preprocessor_info['transform'] == 'boxcox':
                    lambda_val = self.preprocessor_info.get('lambda_boxcox')
                    y_pred_val_orig = self.preprocessor.inverse_boxcox(y_pred_val_scaled, lambda_val)
                    y_true_val_orig = self.preprocessor.inverse_boxcox(y_true_val_scaled, lambda_val)
                elif self.preprocessor_info['transform'] == 'log':
                    y_pred_val_orig = self.preprocessor.inverse_log(y_pred_val_scaled)
                    y_true_val_orig = self.preprocessor.inverse_log(y_true_val_scaled)
                else:
                    y_pred_val_orig = y_pred_val_scaled
                    y_true_val_orig = y_true_val_scaled
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ train –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫
                if len(self.train_data[1].shape) > 1:
                    y_train_flat = self.train_data[1][:, 0]
                else:
                    y_train_flat = self.train_data[1]
                
                y_train_scaled = self.preprocessor.inverse_transform(y_train_flat)
                
                if self.preprocessor_info['transform'] == 'boxcox':
                    y_train_orig = self.preprocessor.inverse_boxcox(
                        y_train_scaled, self.preprocessor_info['lambda_boxcox']
                    )
                elif self.preprocessor_info['transform'] == 'log':
                    y_train_orig = self.preprocessor.inverse_log(y_train_scaled)
                else:
                    y_train_orig = y_train_scaled
                
                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                metrics = self.metrics_calc.calculate_all_metrics(
                    y_true_val_orig, y_pred_val_orig, y_train_orig, seasonality=7
                )
                
                # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
                if np.any(np.isnan(y_pred_val_orig)) or np.any(np.isinf(y_pred_val_orig)):
                    print(f"‚ö†Ô∏è –û–®–ò–ë–ö–ê: NaN/inf –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö –¥–ª—è {model_name}!")
                    continue
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                self.models[model_name] = trainer
                self.results[model_name] = {
                    'metrics': metrics,
                    'time': train_time,
                    'train_losses': train_losses,
                    'val_losses': val_losses,
                    'y_pred': y_pred_val_orig,
                    'y_true': y_true_val_orig,
                }
                
                print(f"‚úÖ {model_name}: MASE={metrics.get('MASE', 'N/A'):.4f}, "
                      f"MAE={metrics.get('MAE', 'N/A'):.2f}, "
                      f"RMSE={metrics.get('RMSE', 'N/A'):.2f} "
                      f"({train_time:.1f}—Å)")
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ {model_name}: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        return self
    
    def evaluate_all_models(self):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        print("\n–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        X_test, y_test, _ = self.test_data
        
        for model_name, trainer in self.models.items():
            try:
                from training import TimeSeriesDataset
                from torch.utils.data import DataLoader
                test_dataset = TimeSeriesDataset(X_test, y_test)
                test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
                
                y_pred_test, y_true_test = trainer.predict(test_loader)
                
                # –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏)
                if len(y_pred_test.shape) > 1:
                    y_pred_test_flat = y_pred_test[:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥
                    y_true_test_flat = y_true_test[:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥
                else:
                    y_pred_test_flat = y_pred_test
                    y_true_test_flat = y_true_test
                
                if self.preprocessor_info['transform'] == 'boxcox':
                    y_pred_test_scaled = self.preprocessor.inverse_transform(y_pred_test_flat)
                    y_true_test_scaled = self.preprocessor.inverse_transform(y_true_test_flat)
                    y_pred_test_orig = self.preprocessor.inverse_boxcox(
                        y_pred_test_scaled,
                        self.preprocessor_info['lambda_boxcox']
                    )
                    y_true_test_orig = self.preprocessor.inverse_boxcox(
                        y_true_test_scaled,
                        self.preprocessor_info['lambda_boxcox']
                    )
                elif self.preprocessor_info['transform'] == 'log':
                    y_pred_test_scaled = self.preprocessor.inverse_transform(y_pred_test_flat)
                    y_true_test_scaled = self.preprocessor.inverse_transform(y_true_test_flat)
                    y_pred_test_orig = self.preprocessor.inverse_log(y_pred_test_scaled)
                    y_true_test_orig = self.preprocessor.inverse_log(y_true_test_scaled)
                else:
                    y_pred_test_orig = self.preprocessor.inverse_transform(y_pred_test_flat)
                    y_true_test_orig = self.preprocessor.inverse_transform(y_true_test_flat)
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                if len(self.train_data[1].shape) > 1:
                    y_train_flat = self.train_data[1][:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥
                else:
                    y_train_flat = self.train_data[1]
                
                y_train_scaled = self.preprocessor.inverse_transform(y_train_flat)
                
                if self.preprocessor_info['transform'] == 'boxcox':
                    y_train_orig = self.preprocessor.inverse_boxcox(
                        y_train_scaled, self.preprocessor_info['lambda_boxcox']
                    )
                elif self.preprocessor_info['transform'] == 'log':
                    y_train_orig = self.preprocessor.inverse_log(y_train_scaled)
                else:
                    y_train_orig = y_train_scaled
                
                metrics = self.metrics_calc.calculate_all_metrics(
                    y_true_test_orig, y_pred_test_orig, y_train_orig, seasonality=7
                )
                
                self.results[model_name]['test_metrics'] = metrics
                self.results[model_name]['test_y_pred'] = y_pred_test_orig
                self.results[model_name]['test_y_true'] = y_true_test_orig
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ {model_name}: {e}")
        
        return self
    
    def create_diagnostics(self):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏."""
        print("\n–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        
        for model_name, result in self.results.items():
            try:
                # Learning curves
                if 'train_losses' in result and 'val_losses' in result:
                    self.diagnostics.plot_learning_curves(
                        result['train_losses'],
                        result['val_losses'],
                        save_path=str(self.output_dir / f"{model_name}_learning_curves.png")
                    )
                
                # –ü—Ä–æ–≥–Ω–æ–∑—ã
                if 'y_pred' in result and 'y_true' in result:
                    self.diagnostics.plot_predictions(
                        result['y_true'],
                        result['y_pred'],
                        save_path=str(self.output_dir / f"{model_name}_predictions.png")
                    )
                
                # –û—Å—Ç–∞—Ç–∫–∏
                if 'y_pred' in result and 'y_true' in result:
                    residuals = result['y_true'] - result['y_pred']
                    self.diagnostics.plot_residual_analysis(
                        residuals,
                        save_path=str(self.output_dir / f"{model_name}_residuals.png")
                    )
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –¥–ª—è {model_name}: {e}")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        try:
            self.diagnostics.plot_model_comparison(
                self.results,
                metric='MASE',
                save_path=str(self.output_dir / "model_comparison.png")
            )
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        
        return self
    
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        comparison_table = self.evaluator.create_comparison_table(self.results, sort_by='MASE')
        comparison_table.to_csv(self.output_dir / "model_comparison.csv", index=False)
        print(f"–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {self.output_dir / 'model_comparison.csv'}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results_summary = {}
        for model_name, result in self.results.items():
            results_summary[model_name] = {
                'metrics': result.get('metrics', {}),
                'test_metrics': result.get('test_metrics', {}),
                'time': result.get('time', 0),
            }
        
        with open(self.output_dir / "results_summary.json", 'w', encoding='utf-8') as f:
            json.dump(results_summary, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.output_dir / 'results_summary.json'}")
        
        return self


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    data_path = os.path.join(os.path.dirname(__file__), 'New_final.csv')
    output_dir = 'results'
    # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã - –±—É–¥—É—Ç —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
    lookback = 336  # ~14 –¥–Ω–µ–π –ø—Ä–∏ –Ω–µ–¥–µ–ª—å–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ (–±—É–¥–µ—Ç —É–º–µ–Ω—å—à–µ–Ω–æ, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ)
    horizon = 48  # ~2 –¥–Ω—è
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    pipeline = DeepLearningPipeline(
        data_path=data_path,
        target_column='Weekly_Sales',
        date_column='Date',
        output_dir=output_dir,
        lookback=lookback,
        horizon=horizon
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    pipeline.load_data() \
            .preprocess_data(apply_transform='boxcox') \
            .train_all_models(epochs=50, batch_size=32) \
            .evaluate_all_models() \
            .create_diagnostics() \
            .save_results()
    
    print("\n" + "="*60)
    print("–ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print("="*60)


if __name__ == "__main__":
    main()

