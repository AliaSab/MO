"""
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import torch
import warnings
import time
from pathlib import Path
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç—ã –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from preprocessing import TimeSeriesPreprocessor
from feature_engineering import FeatureEngineer
from models import create_all_models
from training import train_model, ModelTrainer, TimeSeriesDataset
from torch.utils.data import DataLoader
from evaluation import MetricsCalculator, ModelEvaluator
from diagnostics import ModelDiagnostics

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤",
    page_icon="üß†",
    layout="wide"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
if 'data' not in st.session_state:
    st.session_state.data = None
if 'preprocessor' not in st.session_state:
    st.session_state.preprocessor = TimeSeriesPreprocessor()
if 'models' not in st.session_state:
    st.session_state.models = {}
if 'results' not in st.session_state:
    st.session_state.results = {}
if 'run_training' not in st.session_state:
    st.session_state.run_training = False
if 'training_params' not in st.session_state:
    st.session_state.training_params = {}
if 'device' not in st.session_state:
    st.session_state.device = 'cuda' if torch.cuda.is_available() else 'cpu'

device = st.session_state.device


def load_data(uploaded_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞."""
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith('.parquet'):
            df = pd.read_parquet(uploaded_file)
        else:
            st.error("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ CSV –∏ Parquet —Ñ–∞–π–ª—ã")
            return None
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return None


def prepare_time_series(df, date_column, target_column):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥."""
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π DataFrame
        df = df.copy()
        
        df[date_column] = pd.to_datetime(df[date_column], utc=True)
        if df[date_column].dt.tz is not None:
            df[date_column] = df[date_column].dt.tz_localize(None)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        df = df.sort_values(date_column)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ Store –∏ Dept (–∫–∞–∫ –≤ run_pipeline.py)
        if 'Store' in df.columns and 'Dept' in df.columns:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç –¥–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            unique_dates_before = df[date_column].nunique()
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º –∏ –æ—Ç–¥–µ–ª–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –¥–∞—Ç–∞–º)
            df = df.groupby(date_column)[target_column].mean().reset_index()
            df = df.set_index(date_column)
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            df = df.sort_index()
            
            unique_dates_after = len(df)
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –æ—Å—Ç–∞–ª–æ—Å—å –æ—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
            if unique_dates_after < 100:
                st.warning(f"‚ö†Ô∏è –ü–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –¥–∞—Ç–µ –æ—Å—Ç–∞–ª–æ—Å—å —Ç–æ–ª—å–∫–æ {unique_dates_after} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π "
                          f"(–±—ã–ª–æ {unique_dates_before} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç). "
                          f"–≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –º–∞–ª–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
        else:
            df = df.set_index(date_column)
        
        if target_column not in df.columns:
            st.error(f"–ö–æ–ª–æ–Ω–∫–∞ {target_column} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None, None
        
        y = df[target_column].dropna()
        dates = y.index
        
        return y, dates
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None, None


def plot_predictions_interactive(y_true, y_pred, dates=None, model_name="Model"):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤."""
    fig = go.Figure()
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤—ã –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–ª–∏–Ω—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
    min_len = min(len(y_true), len(y_pred))
    if len(y_true) != len(y_pred):
        y_true = y_true[:min_len]
        y_pred = y_pred[:min_len]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –∏ Inf
    valid_mask = np.isfinite(y_true) & np.isfinite(y_pred)
    if np.sum(valid_mask) == 0:
        # –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        fig.add_annotation(
            text="–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            xref="paper", yref="paper",
            x=0.5, y=0.5, showarrow=False,
            font=dict(size=16)
        )
        return fig
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    y_true = y_true[valid_mask]
    y_pred = y_pred[valid_mask]
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞—Ç—ã
    if dates is not None:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–∞—Å—Å–∏–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        if hasattr(dates, 'tolist'):
            dates_list = np.array(dates.tolist())
        elif hasattr(dates, 'values'):
            dates_list = np.array(dates.values)
        elif isinstance(dates, (list, tuple, np.ndarray)):
            dates_list = np.array(dates)
        else:
            dates_list = np.array([dates])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞—Ç—ã –ø–æ –≤–∞–ª–∏–¥–Ω–æ–π –º–∞—Å–∫–µ
        if len(dates_list) == len(valid_mask):
            dates_list = dates_list[valid_mask]
        elif len(dates_list) > len(valid_mask):
            dates_list = dates_list[:len(valid_mask)][valid_mask[:len(dates_list)]]
        else:
            dates_list = np.array(list(range(len(y_true))))
        
        x_axis = dates_list
    else:
        x_axis = np.array(range(len(y_true)))
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ—á–µ–∫
    if len(y_true) == 1:
        mode_true = 'markers'
        mode_pred = 'markers'
        marker_size = 10
    elif len(y_true) <= 5:
        mode_true = 'markers+lines'
        mode_pred = 'markers+lines'
        marker_size = 8
    else:
        mode_true = 'lines+markers'
        mode_pred = 'lines+markers'
        marker_size = 4
    
    fig.add_trace(go.Scatter(
        x=x_axis,
        y=y_true,
        mode=mode_true,
        name='–§–∞–∫—Ç',
        line=dict(color='blue', width=2) if len(y_true) > 1 else None,
        marker=dict(size=marker_size, color='blue', symbol='circle')
    ))
    
    fig.add_trace(go.Scatter(
        x=x_axis,
        y=y_pred,
        mode=mode_pred,
        name='–ü—Ä–æ–≥–Ω–æ–∑',
        line=dict(color='red', width=2, dash='dash') if len(y_pred) > 1 else None,
        marker=dict(size=marker_size, color='red', symbol='diamond')
    ))
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
    fig.update_layout(
        title=f'–ü—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–∏ {model_name} (—Ç–æ—á–µ–∫: {len(y_true)})',
        xaxis_title='–í—Ä–µ–º—è',
        yaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ',
        hovermode='x unified',
        height=500,
        showlegend=True,
        legend=dict(x=0.02, y=0.98)
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Å–∏ Y –¥–ª—è –±–æ–ª—å—à–∏—Ö —á–∏—Å–µ–ª
    max_val = max(np.max(np.abs(y_true)), np.max(np.abs(y_pred))) if len(y_true) > 0 else 0
    if max_val > 1000:
        fig.update_layout(yaxis=dict(tickformat='.2s'))  # –ù–∞—É—á–Ω–∞—è –Ω–æ—Ç–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö —á–∏—Å–µ–ª
    
    return fig


def plot_learning_curves_interactive(train_losses, val_losses, model_name="Model"):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è."""
    fig = go.Figure()
    
    epochs = range(1, len(train_losses) + 1)
    
    fig.add_trace(go.Scatter(
        x=list(epochs),
        y=train_losses,
        mode='lines',
        name='Train Loss',
        line=dict(color='blue', width=2)
    ))
    
    fig.add_trace(go.Scatter(
        x=list(epochs),
        y=val_losses,
        mode='lines',
        name='Validation Loss',
        line=dict(color='red', width=2)
    ))
    
    fig.update_layout(
        title=f'–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è: {model_name}',
        xaxis_title='Epoch',
        yaxis_title='Loss',
        hovermode='x unified',
        height=400
    )
    
    return fig


def plot_model_comparison_interactive(results_dict, metric='MASE'):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π."""
    model_names = list(results_dict.keys())
    metric_values = []
    
    for name in model_names:
        metrics = results_dict[name].get('metrics', {})
        metric_values.append(metrics.get(metric, np.nan))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º
    sorted_data = sorted(zip(model_names, metric_values), key=lambda x: x[1] if not np.isnan(x[1]) else float('inf'))
    model_names, metric_values = zip(*sorted_data)
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=list(metric_values),
        y=list(model_names),
        orientation='h',
        marker=dict(color='steelblue', opacity=0.7),
        text=[f'{v:.4f}' if not np.isnan(v) else 'N/A' for v in metric_values],
        textposition='outside'
    ))
    
    fig.update_layout(
        title=f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ {metric}',
        xaxis_title=metric,
        yaxis_title='–ú–æ–¥–µ–ª—å',
        height=400 + len(model_names) * 30,
        showlegend=False
    )
    
    return fig


def main():
    st.title("üß† –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
    st.markdown("---")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        st.subheader("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª", type=['csv'])
        
        if uploaded_file is not None:
            if st.session_state.data is None or st.button("–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
                st.session_state.data = load_data(uploaded_file)
                if st.session_state.data is not None:
                    st.success("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        
        if st.session_state.data is not None:
            st.subheader("2. –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫")
            date_columns = [col for col in st.session_state.data.columns 
                          if pd.api.types.is_datetime64_any_dtype(st.session_state.data[col]) or
                          'date' in col.lower() or 'time' in col.lower()]
            
            if not date_columns:
                date_columns = st.session_state.data.columns.tolist()
            
            date_column = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–∞–º–∏", date_columns)
            target_column = st.selectbox("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è", 
                                        st.session_state.data.columns.tolist())
            
            st.subheader("3. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")
            lookback = st.slider("Lookback (–æ–∫–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏)", 24, 500, 336, 
                               help="–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 336 –¥–ª—è –Ω–µ–¥–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ú–µ–Ω—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–µ–Ω–∏–µ")
            horizon = st.selectbox("Horizon (–≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞)", [24, 48, 168], index=1)
            
            st.subheader("4. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞")
            transform_type = st.selectbox("–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è", 
                                         ['boxcox', 'log', 'none'], 
                                         index=0)
            scaler_type = st.selectbox("–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è", 
                                     ['standard', 'minmax'], 
                                     index=0)
            
            st.subheader("5. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è")
            st.markdown("**üí° –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:** epochs=20-30, batch_size=64-128")
            epochs = st.slider("–≠–ø–æ—Ö–∏", 5, 200, 20, 
                             help="–ú–µ–Ω—å—à–µ —ç–ø–æ—Ö = –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–µ–Ω–∏–µ. 20-30 –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å early stopping")
            batch_size = st.slider("Batch size", 16, 256, 64,
                                 help="–ë–æ–ª—å—à–µ batch_size = –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–µ–Ω–∏–µ, –Ω–æ –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏")
            learning_rate = st.selectbox("Learning rate", 
                                        [1e-4, 5e-4, 1e-3, 5e-3, 1e-2], 
                                        index=2)
            optimizer = st.selectbox("–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä", 
                                    ['adam', 'adamw'], 
                                    index=0)
            loss_fn = st.selectbox("–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å", 
                                  ['mse', 'mae', 'huber', 'mse+mae'], 
                                  index=3)
            
            st.subheader("6. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            basic_models = ['MLP', 'DLinear', 'NLinear', 'Naive', 'SeasonalNaive']
            rnn_models = ['RNN', 'LSTM', 'GRU', 'BiLSTM', 'BiGRU']
            advanced_models = ['TCN', 'N-BEATS', 'N-HiTS', 'Transformer', 'CNN-LSTM', 'CNN-GRU']
            sota_models = ['Informer', 'Autoformer', 'PatchTST', 'TFT', 'TCN-Attention', 'LSTM-AE']
            
            model_group = st.radio(
                "–ì—Ä—É–ø–ø–∞ –º–æ–¥–µ–ª–µ–π:",
                ["–ë–∞–∑–æ–≤—ã–µ (–±—ã—Å—Ç—Ä—ã–µ)", "RNN (—Å—Ä–µ–¥–Ω–∏–µ)", "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ (–º–µ–¥–ª–µ–Ω–Ω—ã–µ)", "SOTA (–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ)", "–í—Å–µ"],
                index=0,
                help="–ë–∞–∑–æ–≤—ã–µ - –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, SOTA - —Å–∞–º—ã–µ —Å–ª–æ–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏"
            )
            
            if model_group == "–ë–∞–∑–æ–≤—ã–µ (–±—ã—Å—Ç—Ä—ã–µ)":
                available_models = basic_models
                default_models = ['LSTM', 'DLinear']
            elif model_group == "RNN (—Å—Ä–µ–¥–Ω–∏–µ)":
                available_models = rnn_models
                default_models = ['LSTM', 'GRU']
            elif model_group == "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ (–º–µ–¥–ª–µ–Ω–Ω—ã–µ)":
                available_models = advanced_models
                default_models = ['N-BEATS', 'TCN']
            elif model_group == "SOTA (–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ)":
                available_models = sota_models
                default_models = ['Informer', 'TFT']
            else:
                available_models = basic_models + rnn_models + advanced_models + sota_models
                default_models = ['LSTM', 'DLinear']
            
            st.markdown("**üí° –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–±–µ—Ä–∏—Ç–µ 1-2 –º–æ–¥–µ–ª–∏**")
            selected_models = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏", 
                                            available_models, 
                                            default=[m for m in default_models if m in available_models],
                                            help="–ú–µ–Ω—å—à–µ –º–æ–¥–µ–ª–µ–π = –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–µ–Ω–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—á–∞—Ç—å —Å 1-2 –º–æ–¥–µ–ª–µ–π")
            
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", type="primary"):
                st.session_state.run_training = True
                st.session_state.training_params = {
                    'date_column': date_column,
                    'target_column': target_column,
                    'lookback': lookback,
                    'horizon': horizon,
                    'transform_type': transform_type,
                    'scaler_type': scaler_type,
                    'epochs': epochs,
                    'batch_size': batch_size,
                    'learning_rate': learning_rate,
                    'optimizer': optimizer,
                    'loss_fn': loss_fn,
                    'selected_models': selected_models,
                }
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    if st.session_state.data is None:
        st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏")
        st.markdown("""
        ### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, New_final.csv)
        2. –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–∞–º–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ (lookback, horizon)
        4. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        5. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        6. –ù–∞–∂–º–∏—Ç–µ "–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ"
        
        ### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏:
        - **–ë–∞–∑–æ–≤—ã–µ**: MLP, TCN, N-BEATS
        - **–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ**: RNN, LSTM, GRU, BiLSTM, BiGRU
        - **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã**: Transformer
        - **–ì–∏–±—Ä–∏–¥—ã**: CNN-LSTM, CNN-GRU
        - **–ë–µ–π–∑–ª–∞–π–Ω—ã**: DLinear, NLinear, Naive, SeasonalNaive
        """)
    else:
        # –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö
        with st.expander("üìä –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                st.dataframe(st.session_state.data.head(100))
            with col2:
                st.write(f"**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** {st.session_state.data.shape}")
                st.write(f"**–ö–æ–ª–æ–Ω–∫–∏:** {list(st.session_state.data.columns)}")
        
        # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
        if st.session_state.get('run_training', False) and 'training_params' in st.session_state:
            params = st.session_state.training_params
            try:
                run_training_pipeline(params)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
                import traceback
                st.code(traceback.format_exc())
            finally:
                st.session_state.run_training = False
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if st.session_state.results:
            display_results()


def run_training_pipeline(params):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è."""
    st.header("üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ spinner –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è)
    try:
        st.write("üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        y, dates = prepare_time_series(
            st.session_state.data,
            params['date_column'],
            params['target_column']
        )
        
        if y is None:
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        if len(y) < 100:
            st.warning(f"‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {len(y)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        st.write("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        preprocessor = TimeSeriesPreprocessor(scaler_type=params['scaler_type'])
        transform_type = params['transform_type'] if params['transform_type'] != 'none' else None
        
        (X_train, y_train, train_dates), \
        (X_val, y_val, val_dates), \
        (X_test, y_test, test_dates), \
        preprocessor_info = preprocessor.prepare_data(
            y,
            lookback=params['lookback'],
            horizon=params['horizon'],
            apply_transform=transform_type
        )
        
        st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        st.info(f"üìä **–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã:** X_train={X_train.shape}, y_train={y_train.shape}")
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        st.code(traceback.format_exc())
        return
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    # input_size - —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (features), –∞ –Ω–µ –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    # –î–ª—è –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏, –Ω—É–∂–µ–Ω lookback
    input_size = X_train.shape[2] if len(X_train.shape) == 3 else X_train.shape[1]
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ preprocessor_info (–º–æ–≥—É—Ç –±—ã—Ç—å –∏–∑–º–µ–Ω–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
    actual_lookback = preprocessor_info.get('lookback', params['lookback'])
    actual_horizon = preprocessor_info.get('horizon', params['horizon'])
    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã –≤ –¥–∞–Ω–Ω—ã—Ö
    actual_seq_len = X_train.shape[1] if len(X_train.shape) == 3 else X_train.shape[0]
    actual_y_horizon = y_train.shape[1] if len(y_train.shape) > 1 else 1
    
    st.info(f"üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π:** input_size={input_size}, lookback={actual_lookback}, horizon={actual_horizon}")
    st.info(f"üìä **–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:** X_train={X_train.shape}, y_train={y_train.shape}, "
            f"actual_seq_len={actual_seq_len}, actual_y_horizon={actual_y_horizon}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if actual_seq_len != actual_lookback:
        st.warning(f"‚ö†Ô∏è –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ({actual_seq_len}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å lookback ({actual_lookback}). –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä.")
        actual_lookback = actual_seq_len
    
    if actual_y_horizon != actual_horizon:
        st.warning(f"‚ö†Ô∏è –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –≤ y ({actual_y_horizon}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å horizon ({actual_horizon}). –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä.")
        actual_horizon = actual_y_horizon
    
    results = {}
    models = {}
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö (–≤—ã–≤–æ–¥–∏–º –æ–¥–∏–Ω —Ä–∞–∑)
    st.info(f"üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:** epochs={params['epochs']}, batch_size={params['batch_size']}, "
            f"lookback={actual_lookback}, horizon={actual_horizon}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_container = st.container()
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç—É—Å-–±–∞—Ä –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    status_placeholder = st.empty()
    
    for idx, model_name in enumerate(params['selected_models']):
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            status_placeholder.info(f"üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {idx+1}/{len(params['selected_models'])}: **{model_name}**")
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (lookback –∏ horizon –º–æ–≥—É—Ç –±—ã—Ç—å –∏–∑–º–µ–Ω–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            model = create_all_models(input_size, horizon=actual_horizon, lookback=actual_lookback)[model_name]
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è)
            # –î–ª—è –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π early stopping
            trainer_kwargs = {
                'loss_fn': params['loss_fn'],
                'optimizer': params['optimizer'],
                'lr': params['learning_rate'],
                'weight_decay': 1e-3,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
                'gradient_clip': 1.0,
                'early_stopping_patience': 5,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
                'reduce_lr_patience': 3,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            }
            
            # –û–±—É—á–∞–µ–º –±–µ–∑ verbose –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (–æ—Ç–∫–ª—é—á–∞–µ–º –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å)
            status_placeholder.info(f"‚è≥ –û–±—É—á–µ–Ω–∏–µ {model_name}... (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è)")
            start_time = time.time()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—É—á–µ–Ω–∏–µ
            trainer, train_losses, val_losses = train_model(
                model, X_train, y_train, X_val, y_val,
                batch_size=params['batch_size'],
                epochs=params['epochs'],
                device=device,
                verbose=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—ã–≤–æ–¥ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                **trainer_kwargs
            )
            train_time = time.time() - start_time
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è
            status_placeholder.success(f"‚úÖ {model_name} –æ–±—É—á–µ–Ω –∑–∞ {train_time:.2f} —Å–µ–∫")
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
            val_dataset = TimeSeriesDataset(X_val, y_val)
            val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], 
                                  shuffle=False, num_workers=0, pin_memory=False)
            y_pred_val, y_true_val = trainer.predict(val_loader)
            
            # –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ run_pipeline.py)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —à–∞–≥ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫
            if len(y_pred_val.shape) > 1:
                y_pred_val_flat = y_pred_val[:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
                y_true_val_flat = y_true_val[:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            else:
                y_pred_val_flat = y_pred_val
                y_true_val_flat = y_true_val
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö (—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            # st.write(f"üîç **{model_name}:** –§–æ—Ä–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {y_pred_val.shape}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/inf –ø–µ—Ä–µ–¥ –æ–±—Ä–∞—Ç–Ω–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            if np.any(np.isnan(y_pred_val_flat)) or np.any(np.isinf(y_pred_val_flat)):
                st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN/inf –≤ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö {model_name} –ø–µ—Ä–µ–¥ –æ–±—Ä–∞—Ç–Ω–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–µ–π")
                y_pred_val_flat = np.nan_to_num(y_pred_val_flat, nan=0.0, posinf=1e10, neginf=-1e10)
            
            # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            y_pred_val_scaled = preprocessor.inverse_transform(y_pred_val_flat)
            y_true_val_scaled = preprocessor.inverse_transform(y_true_val_flat)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞—Ç–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            if np.any(np.isnan(y_pred_val_scaled)) or np.any(np.isinf(y_pred_val_scaled)):
                st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN/inf –≤ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö {model_name} –ø–æ—Å–ª–µ –æ–±—Ä–∞—Ç–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏")
                y_pred_val_scaled = np.nan_to_num(y_pred_val_scaled, nan=0.0, posinf=1e10, neginf=-1e10)
            
            if preprocessor_info['transform'] == 'boxcox':
                y_pred_val_orig = preprocessor.inverse_boxcox(
                    y_pred_val_scaled, preprocessor_info['lambda_boxcox']
                )
                y_true_val_orig = preprocessor.inverse_boxcox(
                    y_true_val_scaled, preprocessor_info['lambda_boxcox']
                )
            elif preprocessor_info['transform'] == 'log':
                y_pred_val_orig = preprocessor.inverse_log(y_pred_val_scaled)
                y_true_val_orig = preprocessor.inverse_log(y_true_val_scaled)
            else:
                y_pred_val_orig = y_pred_val_scaled
                y_true_val_orig = y_true_val_scaled
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if np.any(np.isnan(y_pred_val_orig)) or np.any(np.isinf(y_pred_val_orig)):
                st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN/inf –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö {model_name}")
                y_pred_val_orig = np.nan_to_num(y_pred_val_orig, nan=0.0, posinf=1e10, neginf=-1e10)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            metrics_calc = MetricsCalculator()
            if len(y_train.shape) > 1:
                y_train_flat = y_train[:, 0]  # –ü–µ—Ä–≤—ã–π —à–∞–≥
            else:
                y_train_flat = y_train
            
            y_train_scaled = preprocessor.inverse_transform(y_train_flat)
            if preprocessor_info['transform'] == 'boxcox':
                y_train_orig = preprocessor.inverse_boxcox(
                    y_train_scaled, preprocessor_info['lambda_boxcox']
                )
            elif preprocessor_info['transform'] == 'log':
                y_train_orig = preprocessor.inverse_log(y_train_scaled)
            else:
                y_train_orig = y_train_scaled
            
            metrics = metrics_calc.calculate_all_metrics(
                y_true_val_orig, y_pred_val_orig, y_train_orig, seasonality=7
            )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞: –ø–æ—á–µ–º—É MAE = RMSE (—ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤—Å–µ –æ—à–∏–±–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø–æ –º–æ–¥—É–ª—é)
            # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ—á–µ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2 —Ç–æ—á–∫–∏)
            if len(y_true_val_orig) > 0 and len(y_pred_val_orig) > 0:
                errors = np.abs(y_true_val_orig - y_pred_val_orig)
                errors = errors[np.isfinite(errors)]
                if len(errors) > 0 and len(errors) <= 2:
                    # –î–ª—è 1-2 —Ç–æ—á–µ–∫ MAE –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–≤–µ–Ω RMSE, –µ—Å–ª–∏ –æ—à–∏–±–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø–æ –º–æ–¥—É–ª—é
                    # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π
                    pass
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            # –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —à–∞–≥ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ (–∫–∞–∫ –∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫)
            # –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
            y_pred_val_viz = y_pred_val_orig
            y_true_val_viz = y_true_val_orig
            
            models[model_name] = trainer
            results[model_name] = {
                'metrics': metrics,
                'time': train_time,
                'train_losses': train_losses,
                'val_losses': val_losses,
                'y_pred': y_pred_val_viz,  # –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                'y_true': y_true_val_viz,  # –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                'dates': val_dates,
            }
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ {model_name}: {e}")
            import traceback
            st.code(traceback.format_exc())
            continue
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    if models and results:
        st.session_state.models = models
        st.session_state.results = results
        st.success(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π.")
    else:
        st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –¥–∞–Ω–Ω—ã–µ.")


def display_results():
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
    
    results = st.session_state.results
    
    # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    st.subheader("–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫")
    evaluator = ModelEvaluator()
    comparison_table = evaluator.create_comparison_table(results, sort_by='MASE')
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∑–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ "N/A")
    display_table = comparison_table.copy()
    for col in display_table.columns:
        if col != '–ú–æ–¥–µ–ª—å':
            display_table[col] = display_table[col].apply(
                lambda x: 'N/A' if (isinstance(x, float) and np.isnan(x)) or x is None else x
            )
    
    st.dataframe(display_table, use_container_width=True)
    
    # –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ MASE")
        fig_mase = plot_model_comparison_interactive(results, metric='MASE')
        st.plotly_chart(fig_mase, use_container_width=True)
    
    with col2:
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ RMSE")
        fig_rmse = plot_model_comparison_interactive(results, metric='RMSE')
        st.plotly_chart(fig_rmse, use_container_width=True)
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–æ–¥–µ–ª—è–º
    st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–æ–¥–µ–ª—è–º")
    
    selected_model = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞", 
                                 list(results.keys()))
    
    if selected_model:
        model_result = results[selected_model]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("MASE", f"{model_result['metrics'].get('MASE', 'N/A'):.4f}")
            st.metric("MAE", f"{model_result['metrics'].get('MAE', 'N/A'):.4f}")
            st.metric("RMSE", f"{model_result['metrics'].get('RMSE', 'N/A'):.4f}")
        
        with col2:
            st.metric("MAPE", f"{model_result['metrics'].get('MAPE', 'N/A'):.2f}%")
            r2_value = model_result['metrics'].get('R2', np.nan)
            if isinstance(r2_value, (int, float)) and not np.isnan(r2_value):
                st.metric("R2", f"{r2_value:.4f}")
            else:
                st.metric("R2", "N/A")
            st.metric("–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", f"{model_result['time']:.2f} —Å–µ–∫")
        
        # –ì—Ä–∞—Ñ–∏–∫–∏
        st.subheader(f"–ü—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–∏ {selected_model}")
        fig_pred = plot_predictions_interactive(
            model_result['y_true'],
            model_result['y_pred'],
            model_result.get('dates'),
            selected_model
        )
        st.plotly_chart(fig_pred, use_container_width=True)
        
        # –ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è
        if 'train_losses' in model_result and 'val_losses' in model_result:
            st.subheader(f"–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è: {selected_model}")
            fig_learning = plot_learning_curves_interactive(
                model_result['train_losses'],
                model_result['val_losses'],
                selected_model
            )
            st.plotly_chart(fig_learning, use_container_width=True)


if __name__ == "__main__":
    main()

