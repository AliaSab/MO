"""
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö 9 —ç—Ç–∞–ø–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import json
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç—ã –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from feature_engineering import FeatureEngineer
from validation import DataValidator
from models import create_all_models, BaselineModels, ModelTrainer
from diagnostics import ModelDiagnostics
from evaluation import MetricsCalculator, ModelEvaluator, DieboldMarianoTest
from advanced_techniques import AdvancedTechniques
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤",
    page_icon="üìä",
    layout="wide"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
if 'pipeline_results' not in st.session_state:
    st.session_state.pipeline_results = None
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False


def load_data_from_file(file_path='../New_final.csv'):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞."""
    try:
        if os.path.exists(file_path):
            df = pd.read_csv(file_path)
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], utc=True)
                if df['Date'].dt.tz is not None:
                    df['Date'] = df['Date'].dt.tz_localize(None)
            return df
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None


def prepare_time_series(df, target_col='Weekly_Sales', date_col='Date', 
                        group_cols=None, aggregate=False):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥."""
    if group_cols is None:
        group_cols = []
    
    if aggregate and group_cols and all(col in df.columns for col in group_cols):
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è
        agg_dict = {target_col: 'sum'}
        if 'IsHoliday' in df.columns:
            agg_dict['IsHoliday'] = 'max'
        df_grouped = df.groupby(group_cols + [date_col]).agg(agg_dict).reset_index()
        df_grouped = df_grouped.sort_values(date_col)
        date_index = pd.DatetimeIndex(df_grouped[date_col])
        series = df_grouped[target_col]
        is_holiday = df_grouped['IsHoliday'] if 'IsHoliday' in df_grouped.columns else None
    else:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π Store –∏ Dept
        if 'Store' in df.columns and 'Dept' in df.columns:
            first_store = df['Store'].iloc[0]
            first_dept = df['Dept'].iloc[0]
            df_filtered = df[(df['Store'] == first_store) & (df['Dept'] == first_dept)]
        else:
            df_filtered = df
        
        df_sorted = df_filtered.sort_values(date_col)
        date_index = pd.DatetimeIndex(df_sorted[date_col])
        series = df_sorted[target_col]
        is_holiday = df_sorted['IsHoliday'] if 'IsHoliday' in df_sorted.columns else None
    
    return series, date_index, is_holiday


def run_pipeline_quick(df, target_col='Weekly_Sales', date_col='Date', 
                      horizon=7):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞."""
    results = {
        'models': {},
        'metrics': {},
        'predictions': {},
        'train_times': {},
        'feature_importance': {},
        'residuals': {}
    }
    
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        series, date_index, is_holiday = prepare_time_series(
            df, target_col, date_col, group_cols=['Store', 'Dept'], aggregate=False
        )
        
        # –≠—Ç–∞–ø 1: –ò–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_engineer = FeatureEngineer()
        X, y_transformed, transform_info = feature_engineer.create_all_features(
            series, date_index, is_holiday, apply_log=True, apply_boxcox=False
        )
        
        # –≠—Ç–∞–ø 2: –†–∞–∑–±–∏–µ–Ω–∏–µ
        validator = DataValidator(train_ratio=0.6, val_ratio=0.2, test_ratio=0.2)
        X_train, X_val, X_test = validator.chronological_split(X, date_index)
        y_train, y_val, y_test = validator.chronological_split(y_transformed, date_index)
        date_train, date_val, date_test = validator.chronological_split(date_index, date_index)
        
        # –≠—Ç–∞–ø 5: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–≤—Å–µ –º–æ–¥–µ–ª–∏)
        all_models = create_all_models()
        selected_models = all_models
        
        trainer = ModelTrainer()
        for name, model in selected_models.items():
            trainer.add_model(name, model)
        
        # –û–±—É—á–µ–Ω–∏–µ
        train_start = time.time()
        trained_models = trainer.train_all(X_train, y_train)
        train_time_total = time.time() - train_start
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions_val = trainer.predict_all(X_val[:min(len(X_val), 100)])
        
        # –ë–µ–π–∑–ª–∞–π–Ω—ã
        baseline_preds = {}
        baseline_preds['Naive'] = BaselineModels.naive_forecast(y_train, 1)
        baseline_preds['SeasonalNaive'] = BaselineModels.seasonal_naive_forecast(y_train, 7, 1)
        baseline_preds['MovingAverage'] = BaselineModels.moving_average_forecast(y_train, 7, 1)
        
        # –û—Ü–µ–Ω–∫–∞
        evaluator = ModelEvaluator(y_train=y_train, seasonality=7)
        
        all_predictions = {}
        for name, pred in predictions_val.items():
            if len(pred) > 0:
                all_predictions[name] = pred
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–µ–π–∑–ª–∞–π–Ω—ã
        y_val_slice = y_val.iloc[:min(len(y_val), 100)] if isinstance(y_val, pd.Series) else y_val[:min(len(y_val), 100)]
        for name, baseline_pred in baseline_preds.items():
            all_predictions[name] = np.full(len(y_val_slice), baseline_pred[0] if len(baseline_pred) > 0 else y_train.iloc[-1])
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        max_len = max([len(pred) for pred in all_predictions.values()] + [len(y_val_slice)])
        y_val_final = y_val.iloc[:min(max_len, len(y_val))] if isinstance(y_val, pd.Series) else y_val[:min(max_len, len(y_val))]
        
        metrics_df = evaluator.evaluate_all_models(y_val_final, all_predictions)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results['metrics'] = metrics_df.to_dict('records')
        results['predictions'] = {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in all_predictions.items()}
        results['y_true'] = y_val_final.tolist() if isinstance(y_val_final, pd.Series) else y_val_final.tolist()
        results['y_train'] = y_train.tolist() if isinstance(y_train, pd.Series) else y_train.tolist()
        results['dates_val'] = date_val[:len(y_val_final)].strftime('%Y-%m-%d').tolist()
        results['dates_train'] = date_train.strftime('%Y-%m-%d').tolist()
        results['trained_models'] = list(trained_models.keys())
        
        # Feature importance –¥–ª—è —Ç–æ–ø-3
        diagnostics = ModelDiagnostics()
        if 'MASE' in metrics_df.columns:
            top_3 = metrics_df.nsmallest(3, 'MASE')['model'].tolist()
            for model_name in top_3:
                if model_name in trained_models:
                    importance = diagnostics.get_feature_importance(
                        trained_models[model_name], 
                        X_train.columns.tolist(), 
                        model_name
                    )
                    if importance is not None:
                        results['feature_importance'][model_name] = importance.to_dict('records')
        
        # Diebold-Mariano —Ç–µ—Å—Ç
        if len(all_predictions) >= 2:
            model_names = list(all_predictions.keys())[:5]
            min_len = min([len(all_predictions[k]) for k in model_names] + [len(y_val_final)])
            dm_predictions = {k: all_predictions[k][:min_len] for k in model_names}
            # –ü–µ—Ä–µ–¥–∞–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —É—á–µ—Ç–∞ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            dm_results = evaluator.compare_models_dm(y_val_final[:min_len], dm_predictions, h=horizon)
            results['dm_test'] = dm_results.to_dict()
        
        results['success'] = True
        results['n_features'] = X.shape[1]
        results['train_size'] = len(X_train)
        results['val_size'] = len(y_val_final)
        
    except Exception as e:
        results['success'] = False
        results['error'] = str(e)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
    
    return results


def display_comparison(results):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π."""
    if not results.get('success', False):
        st.error("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        return
    
    st.header("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    if 'metrics' in results and results['metrics']:
        metrics_df = pd.DataFrame(results['metrics'])
        
        st.subheader("üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ MASE
        if 'MASE' in metrics_df.columns:
            metrics_df = metrics_df.sort_values('MASE')
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        display_metrics = metrics_df.copy()
        for col in ['MAE', 'RMSE', 'MAPE', 'MASE', 'RMSSE']:
            if col in display_metrics.columns:
                display_metrics[col] = display_metrics[col].apply(lambda x: f"{x:.4f}" if pd.notna(x) else "N/A")
        
        st.dataframe(
            display_metrics[['model', 'MAE', 'RMSE', 'MAPE', 'MASE', 'RMSSE']].head(15),
            use_container_width=True,
            hide_index=True
        )
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
        st.subheader("üìâ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫")
        
        top_10 = metrics_df.head(10)
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('MAE', 'RMSE', 'MASE', 'MAPE'),
            specs=[[{"type": "bar"}, {"type": "bar"}],
                   [{"type": "bar"}, {"type": "bar"}]]
        )
        
        metrics_to_plot = ['MAE', 'RMSE', 'MASE', 'MAPE']
        positions = [(1, 1), (1, 2), (2, 1), (2, 2)]
        
        for metric, pos in zip(metrics_to_plot, positions):
            if metric in top_10.columns:
                fig.add_trace(
                    go.Bar(
                        x=top_10['model'],
                        y=top_10[metric],
                        name=metric,
                        text=[f"{v:.4f}" for v in top_10[metric]],
                        textposition='auto'
                    ),
                    row=pos[0], col=pos[1]
                )
        
        fig.update_layout(
            height=800,
            showlegend=False,
            title_text="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ç–æ–ø-10 –º–æ–¥–µ–ª–µ–π"
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        st.subheader("üîÆ –ü—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–µ–π")
        
        if 'predictions' in results and 'y_true' in results:
            predictions = results['predictions']
            y_true = results['y_true']
            dates_val = results.get('dates_val', [])
            
            # –¢–æ–ø-5 –º–æ–¥–µ–ª–µ–π
            top_5_models = metrics_df.head(5)['model'].tolist()
            
            fig = go.Figure()
            
            # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if dates_val:
                fig.add_trace(go.Scatter(
                    x=dates_val[:len(y_true)],
                    y=y_true,
                    mode='lines',
                    name='–§–∞–∫—Ç',
                    line=dict(color='black', width=3)
                ))
            else:
                fig.add_trace(go.Scatter(
                    y=y_true,
                    mode='lines',
                    name='–§–∞–∫—Ç',
                    line=dict(color='black', width=3)
                ))
            
            # –ü—Ä–æ–≥–Ω–æ–∑—ã —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π
            colors = ['red', 'blue', 'green', 'orange', 'purple']
            for idx, model_name in enumerate(top_5_models):
                if model_name in predictions:
                    pred = predictions[model_name]
                    if isinstance(pred, list):
                        pred = np.array(pred)
                    
                    min_len = min(len(pred), len(y_true))
                    if dates_val:
                        fig.add_trace(go.Scatter(
                            x=dates_val[:min_len],
                            y=pred[:min_len],
                            mode='lines+markers',
                            name=f'{model_name}',
                            line=dict(color=colors[idx % len(colors)], width=2, dash='dash')
                        ))
                    else:
                        fig.add_trace(go.Scatter(
                            y=pred[:min_len],
                            mode='lines+markers',
                            name=f'{model_name}',
                            line=dict(color=colors[idx % len(colors)], width=2, dash='dash')
                        ))
            
            fig.update_layout(
                title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π",
                xaxis_title="–î–∞—Ç–∞" if dates_val else "–ò–Ω–¥–µ–∫—Å",
                yaxis_title="–ó–Ω–∞—á–µ–Ω–∏–µ",
                height=500,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Feature Importance
        if 'feature_importance' in results and results['feature_importance']:
            st.subheader("üéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç–æ–ø-3 –º–æ–¥–µ–ª–∏)")
            
            for model_name, importance_data in list(results['feature_importance'].items())[:3]:
                importance_df = pd.DataFrame(importance_data)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≤–∞–∂–Ω–æ—Å—Ç–∏
                importance_df['abs_importance'] = importance_df['importance'].abs()
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∞–±—Å–æ–ª—é—Ç–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-15
                importance_df = importance_df.sort_values('abs_importance', ascending=False).head(15)
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
                importance_df = importance_df.sort_values('abs_importance', ascending=True)
                
                fig = go.Figure()
                fig.add_trace(go.Bar(
                    x=importance_df['abs_importance'],
                    y=importance_df['feature'],
                    orientation='h',
                    name=model_name,
                    marker=dict(color='steelblue')
                ))
                
                fig.update_layout(
                    title=f"–¢–æ–ø-15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {model_name}",
                    xaxis_title="–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å",
                    yaxis_title="–ü—Ä–∏–∑–Ω–∞–∫",
                    height=400,
                    showlegend=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # Diebold-Mariano —Ç–µ—Å—Ç
        if 'dm_test' in results and results['dm_test']:
            st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (Diebold-Mariano —Ç–µ—Å—Ç)")
            
            try:
                dm_df = pd.DataFrame(results['dm_test'])
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å p-values
                st.markdown("**–¢–∞–±–ª–∏—Ü–∞ p-values:**")
                st.dataframe(dm_df, use_container_width=True)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏–µ
                st.markdown("""
                **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
                - –ó–Ω–∞—á–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ - —ç—Ç–æ **p-values** —Ç–µ—Å—Ç–∞ Diebold-Mariano
                - **p-value < 0.05**: —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ (–æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ª—É—á—à–µ –¥—Ä—É–≥–æ–π)
                - **p-value ‚â• 0.05**: –Ω–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–≥–æ —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ (–º–æ–¥–µ–ª–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã)
                - **"-"** –æ–∑–Ω–∞—á–∞–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —Å–∞–º–æ–π —Å–æ–±–æ–π
                
                **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –í—ã—Å–æ–∫–∏–µ p-values (–±–ª–∏–∑–∫–∏–µ –∫ 1.0) –æ–∑–Ω–∞—á–∞—é—Ç, —á—Ç–æ –º–æ–¥–µ–ª–∏ –¥–∞—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–µ—Ä–∞–∑–ª–∏—á–∏–º—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã. 
                –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø–æ—Ö–æ–∂–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –¥–∞–Ω–Ω—ã–µ.
                """)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∞–±–ª–∏—Ü–µ
                p_values_list = []
                for col in dm_df.columns:
                    for idx in dm_df.index:
                        val = dm_df.loc[idx, col]
                        if val != '-' and isinstance(val, str):
                            try:
                                pval = float(val)
                                if not pd.isna(pval):
                                    p_values_list.append(pval)
                            except:
                                pass
                
                if p_values_list:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        significant_count = sum(1 for p in p_values_list if p < 0.05)
                        st.metric("–ó–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π", f"{significant_count}/{len(p_values_list)}")
                    with col2:
                        avg_pvalue = np.mean(p_values_list)
                        st.metric("–°—Ä–µ–¥–Ω–∏–π p-value", f"{avg_pvalue:.4f}")
                    with col3:
                        min_pvalue = np.min(p_values_list)
                        st.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π p-value", f"{min_pvalue:.4f}")
                    
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å DM —Ç–µ—Å—Ç: {e}")
        
        # –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        st.subheader("‚ÑπÔ∏è –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π", len(metrics_df))
        with col2:
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", results.get('n_features', 'N/A'))
        with col3:
            st.metric("–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏", results.get('train_size', 'N/A'))
        with col4:
            best_model = metrics_df.iloc[0]['model'] if len(metrics_df) > 0 else 'N/A'
            st.metric("–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å", best_model)
        
        if 'MASE' in metrics_df.columns and len(metrics_df) > 0:
            best_mase = metrics_df.iloc[0]['MASE']
            st.metric("–õ—É—á—à–∏–π MASE", f"{best_mase:.4f}")
    
    else:
        st.warning("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")


def main():
    st.title("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
    st.markdown("---")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        st.subheader("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        data_path = st.text_input(
            "–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö",
            value="../New_final.csv",
            help="–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É New_final.csv"
        )
        
        if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", type="primary"):
            with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                df = load_data_from_file(data_path)
                if df is not None:
                    st.session_state.data = df
                    st.session_state.data_loaded = True
                    st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        
        if st.session_state.data_loaded and 'data' in st.session_state:
            st.subheader("2. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞–π–ø–ª–∞–π–Ω–∞")
            
            target_col = st.selectbox(
                "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è",
                ['Weekly_Sales'],
                index=0
            )
            
            horizon = st.selectbox(
                "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è",
                [1, 7, 14, 30],
                index=0,
                help="–î–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–æ—Ä–∏–∑–æ–Ω—Ç 1 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏"
            )
            
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω", type="primary"):
                with st.spinner("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."):
                    results = run_pipeline_quick(
                        st.session_state.data,
                        target_col=target_col,
                        horizon=horizon
                    )
                    st.session_state.pipeline_results = results
                    if results.get('success', False):
                        st.success("–ü–∞–π–ø–ª–∞–π–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                    else:
                        st.error(f"–û—à–∏–±–∫–∞: {results.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    if not st.session_state.data_loaded:
        st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏")
        st.markdown("""
        ### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
        1. –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É `New_final.csv` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `../New_final.csv`)
        2. –ù–∞–∂–º–∏—Ç–µ "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"
        3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
        4. –ù–∞–∂–º–∏—Ç–µ "–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω"
        5. –ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        
        ### –ß—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è:
        - üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (MAE, RMSE, MAPE, MASE, RMSSE)
        - üìâ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
        - üîÆ –ì—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π
        - üéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
        - üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (Diebold-Mariano —Ç–µ—Å—Ç)
        """)
    else:
        if 'data' in st.session_state:
            with st.expander("üìã –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö", expanded=False):
                st.dataframe(st.session_state.data.head(100))
                st.write(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {st.session_state.data.shape}")
        
        if st.session_state.pipeline_results is not None:
            display_comparison(st.session_state.pipeline_results)
        else:
            st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω' –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞")


if __name__ == "__main__":
    main()





