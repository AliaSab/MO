"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ AutoGluon-TimeSeries –≤ –ø–∞–π–ø–ª–∞–π–Ω.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç multiple presets, backtesting, leaderboard –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.
"""

import pandas as pd
import numpy as np
import warnings
import time
warnings.filterwarnings('ignore')

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ AutoGluon
try:
    from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor
    AUTOGLUON_AVAILABLE = True
except ImportError:
    AUTOGLUON_AVAILABLE = False
    print("‚ö†Ô∏è AutoGluon –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏: pip install autogluon.timeseries")


class AutoGluonWrapper:
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è —É–¥–æ–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å AutoGluon-TimeSeries."""
    
    def __init__(self, prediction_length=7, eval_metric="MAE", freq="W"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
        
        Parameters:
        -----------
        prediction_length : int
            –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        eval_metric : str
            –ú–µ—Ç—Ä–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏ ('MAE', 'MAPE', 'MASE', 'RMSE', 'SMAPE')
        freq : str
            –ß–∞—Å—Ç–æ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ ('W' - –Ω–µ–¥–µ–ª—è, 'D' - –¥–µ–Ω—å, 'H' - —á–∞—Å)
        """
        if not AUTOGLUON_AVAILABLE:
            raise ImportError("AutoGluon –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        self.prediction_length = prediction_length
        self.eval_metric = eval_metric
        self.freq = freq
        self.predictors = {}  # –•—Ä–∞–Ω–∏—Ç –æ–±—É—á–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞
        self.training_times = {}
        self.leaderboards = {}
    
    def prepare_data(self, series, date_index, item_id='series_1'):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç pandas Series –≤ TimeSeriesDataFrame –¥–ª—è AutoGluon.
        
        Parameters:
        -----------
        series : pd.Series or np.ndarray
            –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
        date_index : pd.DatetimeIndex
            –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        item_id : str
            –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä—è–¥–∞
        
        Returns:
        --------
        TimeSeriesDataFrame
        """
        if isinstance(series, pd.Series):
            values = series.values
        else:
            values = series
        
        df = pd.DataFrame({
            'item_id': item_id,
            'timestamp': date_index,
            'target': values
        })
        
        # –°–æ–∑–¥–∞–µ–º TimeSeriesDataFrame
        ts_dataframe = TimeSeriesDataFrame.from_data_frame(
            df,
            id_column='item_id',
            timestamp_column='timestamp'
        )
        
        return ts_dataframe
    
    def fit_with_preset(self, train_data, preset="medium_quality", 
                       time_limit=None, verbosity=2):
        """
        –û–±—É—á–∞–µ—Ç AutoGluon —Å –∑–∞–¥–∞–Ω–Ω—ã–º –ø—Ä–µ—Å–µ—Ç–æ–º.
        
        Parameters:
        -----------
        train_data : TimeSeriesDataFrame
            –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        preset : str
            –ü—Ä–µ—Å–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞:
            - 'fast_training': –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            - 'medium_quality': —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            - 'good_quality': —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            - 'high_quality': –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            - 'best_quality': –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        time_limit : int, optional
            –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        verbosity : int
            –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ (0-4)
        
        Returns:
        --------
        TimeSeriesPredictor
        """
        print(f"\nüöÄ –û–±—É—á–µ–Ω–∏–µ AutoGluon —Å –ø—Ä–µ—Å–µ—Ç–æ–º: {preset}")
        print(f"   –ì–æ—Ä–∏–∑–æ–Ω—Ç: {self.prediction_length}, –ú–µ—Ç—Ä–∏–∫–∞: {self.eval_metric}")
        
        predictor = TimeSeriesPredictor(
            target='target',
            prediction_length=self.prediction_length,
            eval_metric=self.eval_metric,
            verbosity=verbosity
        )
        
        start_time = time.time()
        
        fit_kwargs = {
            'train_data': train_data,
            'presets': preset,
            'time_limit': time_limit
        }
        
        predictor.fit(**fit_kwargs)
        
        elapsed = time.time() - start_time
        
        self.predictors[preset] = predictor
        self.training_times[preset] = elapsed
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º leaderboard
        try:
            leaderboard = predictor.leaderboard(train_data, silent=True)
            self.leaderboards[preset] = leaderboard
            print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {elapsed:.2f} —Å–µ–∫")
            print(f"   –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {leaderboard.iloc[0]['model']}")
            print(f"   –õ—É—á—à–∏–π score: {leaderboard.iloc[0]['score_val']:.6f}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å leaderboard: {e}")
        
        return predictor
    
    def fit_multiple_presets(self, train_data, presets=None, time_limit_per_preset=None):
        """
        –û–±—É—á–∞–µ—Ç AutoGluon —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø—Ä–µ—Å–µ—Ç–∞–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.
        
        Parameters:
        -----------
        train_data : TimeSeriesDataFrame
            –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        presets : list, optional
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ—Å–µ—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: medium, high, best_quality)
        time_limit_per_preset : int, optional
            –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∫–∞–∂–¥—ã–π –ø—Ä–µ—Å–µ—Ç
        
        Returns:
        --------
        dict
            –°–ª–æ–≤–∞—Ä—å {preset: predictor}
        """
        if presets is None:
            presets = ["medium_quality", "high_quality", "best_quality"]
        
        print(f"\n{'='*80}")
        print(f"–û–ë–£–ß–ï–ù–ò–ï AUTOGLUON –° –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ú–ò –ü–†–ï–°–ï–¢–ê–ú–ò")
        print(f"{'='*80}")
        print(f"–ü—Ä–µ—Å–µ—Ç—ã: {presets}")
        
        for preset in presets:
            try:
                self.fit_with_preset(
                    train_data, 
                    preset=preset, 
                    time_limit=time_limit_per_preset,
                    verbosity=2
                )
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ø—Ä–µ—Å–µ—Ç–∞ {preset}: {e}")
        
        return self.predictors
    
    def predict(self, test_data=None, preset="medium_quality", quantile_levels=None):
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑.
        
        Parameters:
        -----------
        test_data : TimeSeriesDataFrame, optional
            –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ None, –ø—Ä–æ–≥–Ω–æ–∑ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏ –æ–±—É—á–µ–Ω–∏—è)
        preset : str
            –ö–∞–∫–æ–π –ø—Ä–µ—Å–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
        quantile_levels : list, optional
            –£—Ä–æ–≤–Ω–∏ –∫–≤–∞–Ω—Ç–∏–ª–µ–π –¥–ª—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [0.1, 0.9])
        
        Returns:
        --------
        pd.DataFrame
            –ü—Ä–æ–≥–Ω–æ–∑—ã
        """
        if preset not in self.predictors:
            raise ValueError(f"–ü—Ä–µ—Å–µ—Ç {preset} –Ω–µ –æ–±—É—á–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(self.predictors.keys())}")
        
        predictor = self.predictors[preset]
        
        if test_data is not None:
            predictions = predictor.predict(test_data, quantile_levels=quantile_levels)
        else:
            predictions = predictor.predict(quantile_levels=quantile_levels)
        
        return predictions
    
    def get_leaderboard(self, preset="medium_quality", data=None):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –ª–∏–¥–µ—Ä–æ–≤ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞.
        
        Parameters:
        -----------
        preset : str
            –ü—Ä–µ—Å–µ—Ç
        data : TimeSeriesDataFrame, optional
            –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è train)
        
        Returns:
        --------
        pd.DataFrame
        """
        if preset not in self.predictors:
            raise ValueError(f"–ü—Ä–µ—Å–µ—Ç {preset} –Ω–µ –æ–±—É—á–µ–Ω")
        
        predictor = self.predictors[preset]
        
        if data is not None:
            leaderboard = predictor.leaderboard(data, silent=True)
        else:
            leaderboard = self.leaderboards.get(preset, None)
        
        return leaderboard
    
    def backtesting(self, full_data, num_windows=3, preset="medium_quality"):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç backtesting –≤–∞–ª–∏–¥–∞—Ü–∏—é.
        
        Parameters:
        -----------
        full_data : TimeSeriesDataFrame
            –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        num_windows : int
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–∫–æ–Ω –¥–ª—è backtesting
        preset : str
            –ü—Ä–µ—Å–µ—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        
        Returns:
        --------
        pd.DataFrame
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã backtesting
        """
        print(f"\nüîÑ Backtesting —Å {num_windows} –æ–∫–Ω–∞–º–∏ (–ø—Ä–µ—Å–µ—Ç: {preset})...")
        
        if preset not in self.predictors:
            raise ValueError(f"–ü—Ä–µ—Å–µ—Ç {preset} –Ω–µ –æ–±—É—á–µ–Ω")
        
        predictor = self.predictors[preset]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π backtesting
        results = []
        data_len = len(full_data)
        window_size = data_len // (num_windows + 1)
        
        for i in range(num_windows):
            train_end = window_size * (i + 1)
            test_start = train_end
            test_end = test_start + self.prediction_length
            
            if test_end > data_len:
                break
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            train_slice = full_data.iloc[:train_end]
            test_slice = full_data.iloc[test_start:test_end]
            
            # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            temp_predictor = TimeSeriesPredictor(
                target='target',
                prediction_length=self.prediction_length,
                eval_metric=self.eval_metric,
                verbosity=0
            )
            temp_predictor.fit(train_slice, presets=preset)
            
            # –ü—Ä–æ–≥–Ω–æ–∑
            predictions = temp_predictor.predict(train_slice)
            
            # –û—Ü–µ–Ω–∫–∞
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏ —Ñ–∞–∫—Ç–∞
            pred_values = predictions['mean'].values if 'mean' in predictions.columns else predictions.values
            actual_values = test_slice['target'].values
            
            mae = np.mean(np.abs(pred_values[:len(actual_values)] - actual_values))
            rmse = np.sqrt(np.mean((pred_values[:len(actual_values)] - actual_values) ** 2))
            
            results.append({
                'window': i + 1,
                'train_end': train_end,
                'test_end': test_end,
                'MAE': mae,
                'RMSE': rmse
            })
            
            print(f"  –û–∫–Ω–æ {i+1}/{num_windows}: MAE={mae:.4f}, RMSE={rmse:.4f}")
        
        return pd.DataFrame(results)
    
    def get_feature_importance(self, preset="medium_quality"):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ).
        
        Parameters:
        -----------
        preset : str
            –ü—Ä–µ—Å–µ—Ç
        
        Returns:
        --------
        pd.DataFrame or None
        """
        if preset not in self.predictors:
            return None
        
        predictor = self.predictors[preset]
        
        try:
            importance = predictor.feature_importance()
            return importance
        except:
            print(f"‚ö†Ô∏è Feature importance –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –ø—Ä–µ—Å–µ—Ç–∞ {preset}")
            return None
    
    def compare_presets(self):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–µ—Å–µ—Ç–æ–≤.
        
        Returns:
        --------
        pd.DataFrame
            –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        """
        if not self.predictors:
            print("‚ö†Ô∏è –ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–µ—Å–µ—Ç–æ–≤")
            return None
        
        results = []
        
        for preset in self.predictors.keys():
            leaderboard = self.leaderboards.get(preset)
            
            if leaderboard is not None and len(leaderboard) > 0:
                best_model = leaderboard.iloc[0]
                
                results.append({
                    'preset': preset,
                    'best_model': best_model['model'],
                    'score_val': best_model['score_val'],
                    'training_time': self.training_times.get(preset, np.nan),
                    'n_models': len(leaderboard)
                })
        
        comparison = pd.DataFrame(results)
        comparison = comparison.sort_values('score_val')
        
        return comparison
    
    def save_predictor(self, preset="medium_quality", path="autogluon_model"):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä.
        
        Parameters:
        -----------
        preset : str
            –ü—Ä–µ—Å–µ—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        path : str
            –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        if preset not in self.predictors:
            raise ValueError(f"–ü—Ä–µ—Å–µ—Ç {preset} –Ω–µ –æ–±—É—á–µ–Ω")
        
        predictor = self.predictors[preset]
        predictor.save(path)
        print(f"‚úÖ –ü—Ä–µ–¥–∏–∫—Ç–æ—Ä {preset} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {path}")
    
    def load_predictor(self, path, preset="loaded"):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä.
        
        Parameters:
        -----------
        path : str
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        preset : str
            –ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞
        """
        predictor = TimeSeriesPredictor.load(path)
        self.predictors[preset] = predictor
        print(f"‚úÖ –ü—Ä–µ–¥–∏–∫—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∫–∞–∫ '{preset}'")
        return predictor


def compare_autogluon_vs_custom(autogluon_preds, custom_preds, y_true, 
                                 autogluon_time, custom_time):
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.
    
    Parameters:
    -----------
    autogluon_preds : dict
        –°–ª–æ–≤–∞—Ä—å {preset: predictions} –¥–ª—è AutoGluon
    custom_preds : dict
        –°–ª–æ–≤–∞—Ä—å {model_name: predictions} –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    y_true : array-like
        –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    autogluon_time : dict
        –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è AutoGluon {preset: time}
    custom_time : float
        –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    
    Returns:
    --------
    pd.DataFrame
        –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    """
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    
    results = []
    
    # AutoGluon –º–æ–¥–µ–ª–∏
    for preset, preds in autogluon_preds.items():
        # –ò–∑–≤–ª–µ–∫–∞–µ–º mean predictions –µ—Å–ª–∏ —ç—Ç–æ DataFrame
        if isinstance(preds, pd.DataFrame):
            pred_values = preds['mean'].values if 'mean' in preds.columns else preds.values.flatten()
        else:
            pred_values = preds
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—ã
        min_len = min(len(pred_values), len(y_true))
        pred_values = pred_values[:min_len]
        y_true_slice = y_true[:min_len] if hasattr(y_true, '__getitem__') else y_true
        
        mae = mean_absolute_error(y_true_slice, pred_values)
        rmse = np.sqrt(mean_squared_error(y_true_slice, pred_values))
        
        results.append({
            'model': f'AutoGluon_{preset}',
            'type': 'AutoML',
            'MAE': mae,
            'RMSE': rmse,
            'training_time': autogluon_time.get(preset, np.nan),
            'interpretability': 'Low',
            'flexibility': 'Low',
            'automation': 'High'
        })
    
    # –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–±–µ—Ä–µ–º —Ç–æ–ø-5 –ª—É—á—à–∏—Ö –ø–æ MAE)
    custom_results = []
    for model_name, preds in custom_preds.items():
        if len(preds) > 0:
            min_len = min(len(preds), len(y_true))
            pred_slice = preds[:min_len]
            y_true_slice = y_true[:min_len]
            
            mae = mean_absolute_error(y_true_slice, pred_slice)
            rmse = np.sqrt(mean_squared_error(y_true_slice, pred_slice))
            
            custom_results.append({
                'model': model_name,
                'type': 'Custom',
                'MAE': mae,
                'RMSE': rmse
            })
    
    # –ë–µ—Ä–µ–º —Ç–æ–ø-5 –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    custom_results = sorted(custom_results, key=lambda x: x['MAE'])[:5]
    
    for cr in custom_results:
        results.append({
            'model': cr['model'],
            'type': 'Custom',
            'MAE': cr['MAE'],
            'RMSE': cr['RMSE'],
            'training_time': custom_time / len(custom_preds),  # –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è
            'interpretability': 'High' if 'Linear' in cr['model'] or 'Ridge' in cr['model'] else 'Medium',
            'flexibility': 'High',
            'automation': 'Low'
        })
    
    comparison = pd.DataFrame(results)
    comparison = comparison.sort_values('MAE')
    
    return comparison


def create_autogluon_recommendations(comparison_df):
    """
    –°–æ–∑–¥–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é AutoGluon vs –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
    
    Parameters:
    -----------
    comparison_df : pd.DataFrame
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    
    Returns:
    --------
    dict
        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    """
    # –õ—É—á—à–∞—è AutoGluon –º–æ–¥–µ–ª—å
    ag_models = comparison_df[comparison_df['type'] == 'AutoML']
    best_ag = ag_models.iloc[0] if len(ag_models) > 0 else None
    
    # –õ—É—á—à–∞—è –∫–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å
    custom_models = comparison_df[comparison_df['type'] == 'Custom']
    best_custom = custom_models.iloc[0] if len(custom_models) > 0 else None
    
    recommendations = {
        'summary': {},
        'use_autogluon_when': [],
        'use_custom_when': [],
        'production_strategy': {},
        'retraining_template': {}
    }
    
    if best_ag is not None and best_custom is not None:
        mae_diff = ((best_custom['MAE'] - best_ag['MAE']) / best_custom['MAE']) * 100
        time_diff = best_ag['training_time'] - best_custom['training_time']
        
        recommendations['summary'] = {
            'best_autogluon_model': best_ag['model'],
            'best_custom_model': best_custom['model'],
            'autogluon_mae_advantage': f"{-mae_diff:.2f}%" if mae_diff < 0 else f"{mae_diff:.2f}% worse",
            'autogluon_time': f"{best_ag['training_time']:.2f} sec",
            'custom_time': f"{best_custom['training_time']:.2f} sec"
        }
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AutoGluon
        recommendations['use_autogluon_when'].extend([
            "–ù—É–∂–µ–Ω –±—ã—Å—Ç—Ä—ã–π MVP –∏–ª–∏ proof-of-concept",
            "–û–≥—Ä–∞–Ω–∏—á–µ–Ω—ã —Ä–µ—Å—É—Ä—Å—ã –Ω–∞ feature engineering",
            "–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
            "–ù—É–∂–Ω—ã –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∞–Ω—Å–∞–º–±–ª–∏ –∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏ (DeepAR, TFT)"
        ])
        
        if mae_diff < -5:  # AutoGluon –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ
            recommendations['use_autogluon_when'].append(
                "AutoGluon –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (>5%) - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"
            )
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏
        recommendations['use_custom_when'].extend([
            "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å (LIME, SHAP)",
            "–ù—É–∂–µ–Ω –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∫–∞–∂–¥—ã–º —ç—Ç–∞–ø–æ–º –ø–∞–π–ø–ª–∞–π–Ω–∞",
            "–°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤—ã–±—Ä–æ—Å–æ–≤",
            "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–∞–º—è—Ç–∏/—Ä–∞–∑–º–µ—Ä—É –º–æ–¥–µ–ª–∏"
        ])
        
        if mae_diff > 5:  # –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ
            recommendations['use_custom_when'].append(
                "–ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (>5%)"
            )
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
        if abs(mae_diff) < 5:  # –ú–æ–¥–µ–ª–∏ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω—ã
            recommendations['production_strategy'] = {
                'approach': 'Hybrid',
                'description': '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AutoGluon –¥–ª—è MVP, –∑–∞—Ç–µ–º –ø–µ—Ä–µ–π—Ç–∏ –∫ –∫–∞—Å—Ç–æ–º–Ω—ã–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏',
                'phase_1': 'AutoGluon –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞',
                'phase_2': '–ê–Ω–∞–ª–∏–∑ feature importance –∏–∑ AutoGluon',
                'phase_3': '–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Å–∞–π—Ç–æ–≤',
                'phase_4': 'A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–æ–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤'
            }
        elif mae_diff < -5:
            recommendations['production_strategy'] = {
                'approach': 'AutoGluon-first',
                'description': 'AutoGluon –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ',
                'monitoring': '–û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –º–µ—Ç—Ä–∏–∫',
                'fallback': '–î–µ—Ä–∂–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–∞–∫ backup'
            }
        else:
            recommendations['production_strategy'] = {
                'approach': 'Custom-first',
                'description': '–ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ',
                'optimization': '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ç—é–Ω–∏–Ω–≥ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤',
                'ensemble': '–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å AutoGluon'
            }
        
        # –®–∞–±–ª–æ–Ω –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        recommendations['retraining_template'] = {
            'frequency': 'Weekly or when MASE degrades >10%',
            'steps': [
                'Load new data',
                'Update feature engineering pipeline',
                'Retrain AutoGluon with best preset',
                'Retrain top-3 custom models',
                'Compare on validation set',
                'Deploy best model',
                'Monitor MASE/MAE on production data'
            ],
            'boxcox_recalibration': 'Recalculate lambda on expanded training set',
            'feature_selection': 'Review feature importance quarterly'
        }
    
    return recommendations




